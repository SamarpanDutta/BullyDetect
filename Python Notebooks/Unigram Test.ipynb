{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Unigram Testing\n",
    "\n",
    "This Python Notebook is used for evaluation of the Word2Vec Unigram model. The section is broken down as follows:\n",
    "\n",
    "- Find most similar words from the selected word\n",
    "- Perform Syntactic Analysis\n",
    "- Perform Semantic Analysis\n",
    "- Find uncommon word among a list of words\n",
    "- Find cosine similarity among two words\n",
    "- Find the frequency count of a word\n",
    "- Check if a word is in the model\n",
    "- Print preview a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPC\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\MyPC\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Unigram model\n",
    "FILE = \"C:/Users/MyPC/Desktop/FYP/W2V Models/w2v_reddit_unigram_300d.bin\"\n",
    "model = w2v.load_word2vec_format(FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biopsychology', 0.740115225315094),\n",
       " ('astrochemistry', 0.7391058206558228),\n",
       " ('neuroendocrinologist', 0.7296165227890015),\n",
       " ('nanoscience', 0.7265405058860779),\n",
       " ('neuropharmacology', 0.7247588038444519),\n",
       " ('saltzberg', 0.7157706618309021),\n",
       " ('ethnomusicology', 0.7156946659088135),\n",
       " ('psychobiology', 0.7154250144958496),\n",
       " ('nueroscience', 0.7147186994552612),\n",
       " ('neuropsychiatry', 0.7140935659408569),\n",
       " ('ichthyology', 0.710540235042572),\n",
       " ('molbio', 0.7056220769882202),\n",
       " ('oenology', 0.7056138515472412),\n",
       " ('antropology', 0.7041956186294556),\n",
       " ('biopsych', 0.7037904858589172),\n",
       " ('neuroengineering', 0.7037561535835266),\n",
       " ('nanoengineering', 0.7024978995323181),\n",
       " ('psycholinguistics', 0.7002543210983276),\n",
       " ('bioanthropology', 0.6995773315429688),\n",
       " ('christmann', 0.698868989944458)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell to find most similar words \n",
    "# One word for unigram: dragon, bleach, tottenham\n",
    "# Two words for bigram: dragon_ball, barack_obama (UNDERSCORE NEEDED + BIGRAM MODEL LOADED)\n",
    "model.most_similar(\"neuropsychopharmacology\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lumpur', 0.6737101674079895),\n",
       " ('kuala', 0.6668090224266052),\n",
       " ('taipei', 0.6401477456092834),\n",
       " ('bangkok', 0.6113026142120361),\n",
       " ('penang', 0.5809809565544128),\n",
       " ('lampur', 0.5752942562103271),\n",
       " ('toyko', 0.5550657510757446),\n",
       " ('selangor', 0.5511509776115417),\n",
       " ('singapore', 0.5502724647521973),\n",
       " ('mumbai', 0.5481346249580383)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell for semantic evaluation (Ex. King - man + woman is approximately equal to queen)\n",
    "model.most_similar(positive=[\"tokyo\",\"malaysia\"], negative=[\"japan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blueish', 0.7298511266708374),\n",
       " ('greyish', 0.7232707738876343),\n",
       " ('bluish', 0.7149738669395447),\n",
       " ('pinkish', 0.705883264541626),\n",
       " ('purplish', 0.7028074264526367),\n",
       " ('brownish', 0.6946163773536682),\n",
       " ('grayish', 0.6922476887702942),\n",
       " ('reddish', 0.6911346316337585),\n",
       " ('yellowish', 0.6770833134651184),\n",
       " ('whitish', 0.6669460535049438)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell for syntactic evaluation (Ex. walking - walk + swim is approximately equal to swimming)\n",
    "model.most_similar(positive=[\"greenish\",\"blue\"], negative=[\"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell to check which word doesn't match among a group of words\n",
    "model.doesnt_match(\"blue green yellow apple\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24046405589195533"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell to check similarity among two words\n",
    "model.similarity(\"titanic\",\"rose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820275"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of times a specific word occured in the 2015 Dataset\n",
    "model.vocab['neuropsychopharmacology'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if word (Unigram) is in model. It is case-sensitive\n",
    "'Dragon' in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pwff\n",
      "1 akorem\n",
      "2 neurodevelopment\n",
      "3 settimana\n",
      "4 mundoek\n",
      "5 chiusa\n",
      "6 bloodwing\n",
      "7 smugpost\n",
      "8 hahahahha\n",
      "9 xforwarding\n",
      "10 parthians\n",
      "11 thomasriggs\n",
      "12 ploped\n",
      "13 ridiculas\n",
      "14 moneycards\n",
      "15 javagunner\n",
      "16 throwwn\n",
      "17 machiner\n",
      "18 sabrinas\n",
      "19 bluffcatching\n",
      "20 resloution\n",
      "21 deaply\n",
      "22 vaxxon\n",
      "23 sadko\n",
      "24 dysgenics\n",
      "25 resante\n",
      "26 siwash\n",
      "27 guitarra\n",
      "28 remmind\n",
      "29 dottinger\n",
      "30 weegeemontage\n",
      "31 chism\n",
      "32 engblom\n",
      "33 lampposts\n",
      "34 hoowdy\n",
      "35 sysmic\n",
      "36 underslung\n",
      "37 greving\n",
      "38 ironfest\n",
      "39 yanaginagi\n",
      "40 kobuleti\n",
      "41 wthings\n",
      "42 peoplebeingjerks\n",
      "43 neropathy\n",
      "44 mediterrainian\n",
      "45 drachmas\n",
      "46 frontsides\n",
      "47 illuminati\n",
      "48 shittyly\n",
      "49 stalkerazzi\n",
      "50 mths\n",
      "51 guney\n",
      "52 fappi\n",
      "53 scootablue\n",
      "54 onrpg\n",
      "55 municipalty\n",
      "56 captured\n",
      "57 monosteel\n",
      "58 subsitiute\n",
      "59 skrrt\n",
      "60 slyvannis\n",
      "61 leet\n",
      "62 lanzando\n",
      "63 springboro\n",
      "64 strobelight\n",
      "65 yourwelf\n",
      "66 zimperium\n",
      "67 boodabooda\n",
      "68 supreriority\n",
      "69 munhall\n",
      "70 circlejerkery\n"
     ]
    }
   ],
   "source": [
    "# A brief review of words in the model\n",
    "count = 70\n",
    "\n",
    "for index, word in enumerate(model.vocab):\n",
    "    print(index, word)\n",
    "    if index == count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list('neuroendocrinologist'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
