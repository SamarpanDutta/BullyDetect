{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Unigram Testing\n",
    "\n",
    "This Python Notebook is used for evaluation of the Word2Vec Unigram model. The section is broken down as follows:\n",
    "\n",
    "- Find most similar words from the selected word\n",
    "- Perform Syntactic Analysis\n",
    "- Perform Semantic Analysis\n",
    "- Find uncommon word among a list of words\n",
    "- Find cosine similarity among two words\n",
    "- Find the frequency count of a word\n",
    "- Check if a word is in the model\n",
    "- Feature vectors of a certain word\n",
    "- Visualisation of words in Vector Space using TSNE\n",
    "- Histogram to showcase distribution of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Unigram model\n",
    "FILE = \"C:/Users/MyPC/Desktop/Vegito/W2V Models/w2v_reddit_unigram_300d.bin\"\n",
    "model = w2v.load_word2vec_format(FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cell to find most similar words \n",
    "# One word for unigram: dragon, bleach, tottenham\n",
    "# Two words for bigram: dragon_ball, barack_obama (UNDERSCORE NEEDED + BIGRAM MODEL LOADED)\n",
    "model.most_similar(\"neuropsychopharmacology\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cell for semantic evaluation (Ex. King - man + woman is approximately equal to queen)\n",
    "model.most_similar(positive=[\"tokyo\",\"malaysia\"], negative=[\"japan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cell for syntactic evaluation (Ex. walking - walk + swim is approximately equal to swimming)\n",
    "model.most_similar(positive=[\"greenish\",\"blue\"], negative=[\"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cell to check which word doesn't match among a group of words\n",
    "model.doesnt_match(\"blue green yellow apple\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cell to check similarity among two words\n",
    "model.similarity(\"squats\",\"legpress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count number of times a specific word occured in the 2015 Dataset\n",
    "word = model.vocab['difu']\n",
    "type(word.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if word (Unigram) is in model. It is case-sensitive\n",
    "'Dragon' in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What does each word actually contain?\n",
    "model['goku']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualisation (Normal) using TSNE and PCA\n",
    "# Motivation: http://lvdmaaten.github.io/tsne/\n",
    "# Motivation: https://golog.co/blog/article/Visualising_high-dimensional_datasets_using_PCA_and_tSNE\n",
    "# Video: https://www.youtube.com/watch?v=RJVL80Gg3lA\n",
    "\n",
    "# Firstly: Import the libraries\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mpld3\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create function to return list of words and word embeddings\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def getEmbeddings(cluster_file, N, word):\n",
    "    \n",
    "    # Specify path\n",
    "    FILE_DICT = \"C:/Users/MyPC/Desktop/Vegito/Word Dictionaries/dict_\" + str(cluster_file) + \"C.pk\"\n",
    "    FILE_CLUS = \"C:/Users/MyPC/Desktop/Vegito/K-Means Models/full_\" + str(cluster_file) + \"C.pk\"\n",
    "    \n",
    "    # Load the files using pickle\n",
    "    array_dict_cluster = pickle.load(open(FILE_DICT, \"rb\"))\n",
    "    word_centroid_map =  pickle.load(open(FILE_CLUS,\"rb\"))\n",
    "    \n",
    "    # Find index number of word \n",
    "    # Then load all related words \n",
    "    cluster_num = word_centroid_map[word]\n",
    "    words_list = array_dict_cluster[cluster_num]['word_list']\n",
    "    \n",
    "    # Get index number of searched word\n",
    "    index_num = words_list.index(word)\n",
    "    print(\"INDEX NUMBER: %i\" % (index_num))\n",
    "    \n",
    "    # Memory limitations\n",
    "    if index_num < N:\n",
    "        \n",
    "        index_num = N\n",
    "    \n",
    "    # Lets get only the first N number of words\n",
    "    words_list = words_list[:index_num + 10]\n",
    "    \n",
    "    # Initialize array of vectors and words\n",
    "    vectors = []\n",
    "    words = []\n",
    "    \n",
    "    # Add vector and words\n",
    "    for word in words_list:\n",
    "        \n",
    "        vectors.append(model[word]) \n",
    "        words.append(word)\n",
    "    \n",
    "    return vectors, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the graph in this cell\n",
    "import time\n",
    "\n",
    "# Get the feature vectors and respective words\n",
    "search_word = 'dickbag'.lower()\n",
    "get_words = 1200\n",
    "\n",
    "wv, vocabulary = getEmbeddings(500, get_words, search_word)\n",
    "\n",
    "print('SEARCHED WORD: %s' % (search_word))\n",
    "print(\"TOTAL WORDS: %i \" % (len(vocabulary)))\n",
    "\n",
    "# Initialize PCA model\n",
    "pca = PCA(n_components=150)\n",
    "\n",
    "start = time.time()\n",
    "pca_result = pca.fit_transform(wv)\n",
    "end = time.time()\n",
    "\n",
    "print(\"TIME TAKEN (PCA): \", end-start)\n",
    "\n",
    "# Get explained variance ratio\n",
    "explain_ratio = np.sum(pca.explained_variance_ratio_)\n",
    "print('EXPLAINED VARIANCED RATIO: ', explain_ratio)\n",
    "\n",
    "# Initialize TSNE model\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "# Fit with TSNE\n",
    "start = time.time()\n",
    "Y = tsne.fit_transform(pca_result)\n",
    "end = time.time()\n",
    "\n",
    "print(\"TIME TAKEN (TSNE): \", end - start)\n",
    "\n",
    "# Scatter points\n",
    "fig, ax = plt.subplots(figsize=(10, 8),subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "# Use Scatterplot\n",
    "ax.scatter(Y[:, 0], Y[:, 1], color=\"blue\")\n",
    "\n",
    "# Initialize Points\n",
    "for label, x, y in zip(vocabulary, Y[:, 0], Y[:, 1]):\n",
    "    \n",
    "    # Give the searched word a different color\n",
    "    # Otherwise, all words should be colored red\n",
    "    color = 'black'\n",
    "    fontsize = 10\n",
    "    \n",
    "    if label == search_word:\n",
    "        color = 'red'\n",
    "        fontsize = 20\n",
    "        \n",
    "    ax.annotate(label, xy=(x, y), fontsize=fontsize, color=color)\n",
    "\n",
    "# Display\n",
    "mpld3.display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to plot the histogram of word distribution\n",
    "\n",
    "def plotHistogram(file_cluster):\n",
    "    \n",
    "    FILE_DICT = \"C:/Users/MyPC/Desktop/Vegito/Word Dictionaries/dict_\" + str(file_cluster) + \"C.pk\"\n",
    "    array_dict_cluster = pickle.load(open(FILE_DICT, \"rb\"))\n",
    "\n",
    "    word_length = []\n",
    "\n",
    "    # Loop cluster by cluster\n",
    "    for cluster in array_dict_cluster:\n",
    "\n",
    "        # Get total words\n",
    "        total_words = len(cluster['word_list'])\n",
    "\n",
    "        # Append\n",
    "        word_length.append(total_words)\n",
    "\n",
    "    # Plot Histogram\n",
    "    PADDING = 15\n",
    "\n",
    "    sns.set(rc={\"figure.figsize\": (6,6)})\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"notebook\", font_scale=1)\n",
    "\n",
    "    ax = sns.distplot(word_length, kde=False, color='purple')\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.set(title='Words Distribution in '+ str(file_cluster) + ' Clusters')\n",
    "\n",
    "    plt.xlabel(\"Total Words\", labelpad=PADDING)\n",
    "    plt.ylabel(\"Total Clusters\", labelpad=PADDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call histogram function plot the histograms\n",
    "\n",
    "mpld3.disable_notebook()\n",
    "# Array to store number of clusters\n",
    "clust_array = [250,500]\n",
    "\n",
    "# Go one by one\n",
    "for clusters in clust_array:\n",
    "    \n",
    "    # Call histogram function\n",
    "    plotHistogram(clusters)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
