{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Evaluation\n",
    "\n",
    "This Python notebook is used for evaluation of a dictionary that is produced by:\n",
    "\n",
    "- Find the cluster a word belongs to \n",
    "- Find the other words in the cluster for a specific word\n",
    "- Compare between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "# Specify the files\n",
    "FILE_DICT_500 = \"C:/Users/MyPC/Desktop/Vegito/Word Dictionaries/dict_500C.pk\"\n",
    "FILE_CLUS_500 = \"C:/Users/MyPC/Desktop/Vegito/K-Means Models/full_500C.pk\"\n",
    "\n",
    "# Load using pickle\n",
    "array_dict_cluster_500 = pickle.load(open(FILE_DICT_500, \"rb\"))\n",
    "word_centroid_map_500 =  pickle.load(open(FILE_CLUS_500,\"rb\"))\n",
    "\n",
    "total_clusters_500 = max(word_centroid_map_500.values()) + 1\n",
    "\n",
    "average_word_500 = round(len(word_centroid_map_500)/total_clusters_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER WORD TO SEARCH: kimchee\n",
      "SEARCHED WORD: kimchee \n",
      "\n",
      "TOTAL WORDS: 1565 \n",
      "\n",
      "\n",
      "\n",
      "feijoada  bechamel  jarlsberg  fries  \n",
      "\n",
      "makhani  tonkotsu  flautas  potpie  \n",
      "\n",
      "toppings  sweetcorn  parsnip  cubed  \n",
      "\n",
      "veg  marinades  perrins  chipotles  \n",
      "\n",
      "oyster  appetizers  egss  sauceless  \n",
      "\n",
      "lunchmeat  bisque  kofta  blanch  \n",
      "\n",
      "microwaveable  umami  chops  marzu  \n",
      "\n",
      "kapsalon  cheddars  scrambled  filet  \n",
      "\n",
      "breakfasty  haggis  babyback  kimchee  \n",
      "\n",
      "rosemary  tefal  cookery  loaf  \n",
      "\n",
      "freschetta  marinara  peperoni  flatbread  \n",
      "\n",
      "tofurkey  teryaki  basashi  seafood  \n",
      "\n",
      "guajillo  serranos  omelets  yuca  \n",
      "\n",
      "marinading  mignon  laksa  kimbap  \n",
      "\n",
      "rotisserie  mussels  yam  sourdough  \n",
      "\n",
      "beetroot  crockpot  kohlrabi  fraiche  \n",
      "\n",
      "horseradish  oxtail  quesadillas  riblets  \n",
      "\n",
      "jalapenos  livermush  bleu  entree  \n",
      "\n",
      "nutribullet  sundried  berbere  saucepan  \n",
      "\n",
      "frittata  baozi  sauteeing  piccata  \n",
      "\n",
      "gefilte  tenderizing  dollop  calrose  \n",
      "\n",
      "tarragon  bannock  sesame  mapo  \n",
      "\n",
      "grater  schmaltz  havarti  zoodles  \n",
      "\n",
      "spinach  sausages  beans  avo  \n",
      "\n",
      "parsely  chilies  salted  corn  \n",
      "\n",
      "zoodle  chicken  zuccini  chirashi  \n",
      "\n",
      "caraway  stromboli  pakoras  portioned  \n",
      "\n",
      "yakiniku  boxty  limes  griller  \n",
      "\n",
      "cashews  cassoulet  pepperoni  scalloped  \n",
      "\n",
      "veganize  tortellini  cuisine  tapenade  \n",
      "\n",
      "banchan  ceviche  plateful  lowfat  \n",
      "\n",
      "yucateco  spatchcocking  noddles  schnitzels  \n",
      "\n",
      "bunless  carnitas  masalas  tacos  \n",
      "\n",
      "stroganoff  frenched  stouffers  pancetta  \n",
      "\n",
      "ketchup  crema  pork  cooks  \n",
      "\n",
      "leeks  gourmet  freekeh  cauli  \n",
      "\n",
      "minestrone  charbroiled  pickled  borscht  \n",
      "\n",
      "omlet  tajine  rellenos  tbs  \n",
      "\n",
      "mustard  viding  karaage  garni  \n",
      "\n",
      "enoki  sourcream  portabello  vegitables  "
     ]
    }
   ],
   "source": [
    "# Find the cluster of words, based on a given word\n",
    "search = input(\"ENTER WORD TO SEARCH: \")\n",
    "\n",
    "# Get the key, or cluster number\n",
    "# NOTE: Different clusters can have same results\n",
    "cluster_num_500 = word_centroid_map_500[search]\n",
    "\n",
    "# Return the array based on the cluster number\n",
    "words_500 = array_dict_cluster_500[cluster_num_500]['word_list']\n",
    "\n",
    "# Randomly subsample 200 words\n",
    "words = random.sample(words_500, 200)\n",
    "\n",
    "# Display results\n",
    "print(\"SEARCHED WORD: %s \\n\" % (search))\n",
    "\n",
    "print(\"TOTAL WORDS: %i \\n\" % (len(words_500)))\n",
    "\n",
    "# Pretty Printing\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    if i % 5 != 0:\n",
    "        print(word, \" \", end=\"\")\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
