{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Evaluation\n",
    "\n",
    "This Python notebook is used for evaluation of a dictionary that is produced by:\n",
    "\n",
    "- Find the cluster a word belongs to \n",
    "- Find the other words in the cluster for a specific word\n",
    "- Compare between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL WORDS: 1146604 \n",
      "\n",
      "AVERAGE PER CLUSTER (250): 4586\n",
      "AVERAGE PER CLUSTER (500): 2293\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the files\n",
    "FILE_DICT_250 = \"C:/Users/MyPC/Desktop/FYP/Word Dictionaries/dict_250C.pk\"\n",
    "FILE_CLUS_250 = \"C:/Users/MyPC/Desktop/FYP/K-Means Models/full_250C.pk\"\n",
    "\n",
    "FILE_DICT_500 = \"C:/Users/MyPC/Desktop/FYP/Word Dictionaries/dict_500C.pk\"\n",
    "FILE_CLUS_500 = \"C:/Users/MyPC/Desktop/FYP/K-Means Models/full_500C.pk\"\n",
    "\n",
    "# Load using pickle\n",
    "array_dict_cluster_250 = pickle.load(open(FILE_DICT_250, \"rb\"))\n",
    "word_centroid_map_250 =  pickle.load(open(FILE_CLUS_250,\"rb\"))\n",
    "\n",
    "array_dict_cluster_500 = pickle.load(open(FILE_DICT_500, \"rb\"))\n",
    "word_centroid_map_500 =  pickle.load(open(FILE_CLUS_500,\"rb\"))\n",
    "\n",
    "total_clusters_250 = max(word_centroid_map_250.values()) + 1\n",
    "total_clusters_500 = max(word_centroid_map_500.values()) + 1\n",
    "\n",
    "average_word_250 = round(len(word_centroid_map_250)/total_clusters_250)\n",
    "average_word_500 = round(len(word_centroid_map_500)/total_clusters_500)\n",
    "\n",
    "# Display results\n",
    "print(\"TOTAL WORDS: %i \\n\" % (len(word_centroid_map_250)))\n",
    "\n",
    "print(\"AVERAGE PER CLUSTER (250): %i\" % (average_word_250))\n",
    "print(\"AVERAGE PER CLUSTER (500): %i\" % (average_word_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCHED WORD: gives \n",
      "\n",
      "TOTAL WORDS (250): 1817\n",
      "TOTAL WORDS (500): 1539 \n",
      "\n",
      "WORDS (250):  ['transcended', 'obliges', 'instigates', 'consists', 'jizzes', 'overvalues', 'ownes', 'fantasizes', 'lessens', 'prepares', 'rests', 'sees', 'mistook', 'symbolises', 'narrows', 'reconfigures', 'recaptures', 'handwaves', 'undertakes', 'dumps', 'regroups', 'suceeds', 'vacillates', 'clobbers', 'inhales', 'determines', 'energizes', 'befuddles', 'consideres', 'dies', 'gushes', 'regurgitates', 'terminates', 'poaches', 'retreats', 'faints', 'slaughters', 'rouses', 'defaces', 'overthinks', 'unfreezes', 'reanimates', 'conserves', 'oozes', 'gropes', 'antagonises', 'evades', 'scares', 'trashes', 'skimps', 'explains', 'enters', 'swears', 'mantains', 'saps', 'debases', 'mismanages', 'entertains', 'whithers', 'tidies', 'hijacks', 'infers', 'foists', 'talks', 'corrects', 'recurs', 'camouflages', 'adheres', 'decries', 'dabbles', 'dispatches', 'showcases', 'mashes', 'thrives', 'loves', 'revitalizes', 'raises', 'navigates', 'officiates', 'attracts', 'threatens', 'abandons', 'outshines', 'endures', 'bastardizes', 'repulses', 'obsesses', 'unrolls', 'acknowledges', 'fascinates', 'nourishes', 'ignites', 'avoids', 'disrespects', 'mishears', 'imprisons', 'detaches', 'injects', 'appropriates', 'relies', 'reorganizes', 'distrusts', 'explodes', 'unseats', 'surrenders', 'monetizes', 'surpresses', 'dictates', 'jeopardizes', 'pussyfoots', 'perseveres', 'hoists', 'contorts', 'reconciles', 'sodomizes', 'wonders', 'vanishes', 'exemplifies', 'peddles', 'caters', 'diverts', 'derails', 'admires', 'overwhelms', 'abbreviates', 'slips', 'disfigures', 'locates', 'struggles', 'condemns', 'cajoles', 'grosses', 'provokes', 'downplays', 'grovels', 'vomits', 'relives', 'portrays', 'disagrees', 'oppresses', 'overrode', 'pronounces', 'eats', 'incites', 'divides', 'enforces', 'sustains', 'clarifies', 'surpasses', 'harks', 'destructs', 'unnerves', 'customizes', 'rectifies', 'declares', 'abhors', 'beheads', 'hypnotizes', 'outweighs', 'reuses', 'alters', 'preceeds', 'admonishes', 'spurns', 'envelops', 'concurs', 'remains', 'decimates', 'scours', 'deigns', 'tramples', 'veers', 'unlearns', 'travels', 'introduces', 'bypasses', 'prowls', 'depresses', 'giveth', 'survives', 'mopes', 'subdues', 'weakens', 'divulges', 'absorbs', 'trys', 'muddles', 'detects', 'goads', 'secludes', 'waltzes', 'saddens', 'churns', 'falsifies', 'normalizes', 'tarnishes', 'arrives', 'aborts', 'panicks', 'dissapears'] \n",
      "\n",
      "\n",
      "WORDS (500):  ['embarasses', 'refers', 'dines', 'endears', 'discusses', 'strangles', 'generalizes', 'slaps', 'expels', 'rekindles', 'progresses', 'dissapoints', 'outgrows', 'squanders', 'confronts', 'coincides', 'mentions', 'becames', 'waits', 'widens', 'regurgitates', 'buttfucks', 'confirms', 'beleives', 'compels', 'matters', 'unfreezes', 'misleads', 'bankrupts', 'chugs', 'hijacks', 'personifies', 'conserves', 'pollutes', 'culminates', 'patronizes', 'desecrates', 'whinges', 'repels', 'helps', 'despairs', 'assimilates', 'decorates', 'obsesses', 'stabilizes', 'strategizes', 'works', 'recalibrates', 'despises', 'empowers', 'unbalances', 'imposes', 'dissects', 'horrifies', 'disassembles', 'trounces', 'gravitates', 'collides', 'squashes', 'shuns', 'behaves', 'consists', 'looves', 'enhances', 'depletes', 'resents', 'afflicts', 'haunts', 'wisens', 'emerges', 'outclasses', 'precedes', 'disrespects', 'simplifies', 'derides', 'resolves', 'sweetens', 'uses', 'energises', 'seeks', 'steamrolls', 'underperforms', 'empathizes', 'recieves', 'circulates', 'handles', 'guilts', 'embodies', 'borrows', 'breathes', 'puts', 'nags', 'oversells', 'obstructs', 'visualises', 'entices', 'spreads', 'embeds', 'evades', 'acts', 'permeates', 'furthers', 'extrapolates', 'maims', 'detonates', 'saturates', 'sexualizes', 'dissappears', 'occupies', 'disgusts', 'donates', 'poses', 'exhibits', 'belives', 'waltzes', 'regresses', 'serves', 'eliminates', 'maximizes', 'warms', 'bares', 'overhears', 'angers', 'lurks', 'misses', 'critizes', 'resonates', 'dislikes', 'diminishes', 'pulls', 'succeeds', 'imitates', 'randomizes', 'subscribes', 'undervalues', 'implicates', 'overwhelms', 'directs', 'decimates', 'focusses', 'tempts', 'prays', 'relys', 'refrains', 'snuffs', 'adores', 'deflates', 'nosedives', 'pervades', 'makes', 'envisions', 'reconsiders', 'amasses', 'knocks', 'unveils', 'interjects', 'animates', 'detaches', 'indulges', 'hallucinates', 'displeases', 'foists', 'wrangles', 'mitigates', 'chastises', 'navigates', 'meditates', 'defeats', 'jizzes', 'characterizes', 'fends', 'tames', 'underrates', 'entrusts', 'retreats', 'unfucks', 'disengages', 'enlists', 'clarifies', 'recognises', 'veers', 'rises', 'befriends', 'manages', 'backfires', 'verifies', 'rambles', 'adds', 'outperforms', 'reopens', 'wallows', 'convinces', 'retains', 'inflates', 'unfolds', 'explores', 'accuses', 'neuters', 'creats', 'scours']\n"
     ]
    }
   ],
   "source": [
    "# Find the cluster of words, based on a given word\n",
    "search = \"gives\"\n",
    "\n",
    "# Get the key, or cluster number\n",
    "# NOTE: Different clusters can have same results\n",
    "cluster_num_250 = word_centroid_map_250[search]\n",
    "cluster_num_500 = word_centroid_map_500[search]\n",
    "\n",
    "# Return the array based on the cluster number\n",
    "words_250 = array_dict_cluster_250[cluster_num_250]['word_list']\n",
    "words_500 = array_dict_cluster_500[cluster_num_500]['word_list']\n",
    "\n",
    "# Display results\n",
    "print(\"SEARCHED WORD: %s \\n\" % (search))\n",
    "\n",
    "print(\"TOTAL WORDS (250): %i\" % (len(words_250)))\n",
    "print(\"TOTAL WORDS (500): %i \\n\" % (len(words_500)))\n",
    "\n",
    "print(\"WORDS (250): \", words_250[:200], \"\\n\\n\")\n",
    "print(\"WORDS (500): \", words_500[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go 378\n",
      "to 378\n",
      "hell 378\n",
      "you 119\n",
      "stupid 122\n",
      "maggot 373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE = \"go to hell you stupid maggot\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Pre-allocate the bag of centroids vector (for speed)\n",
    "bag_of_centroids = np.zeros( total_clusters_500, dtype=\"float32\" )\n",
    "\n",
    "# Loop word by word\n",
    "for word in SENTENCE.split():\n",
    "    \n",
    "    # Check if word is in dictionary\n",
    "    if word in word_centroid_map_500:\n",
    "        \n",
    "        # Get index of the word\n",
    "        index = word_centroid_map_500[word]\n",
    "        \n",
    "        # Print for evalution\n",
    "        print(word, index)\n",
    "        \n",
    "        # Increment index of bag_of_centroids\n",
    "        bag_of_centroids[index] += 1\n",
    "\n",
    "bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
