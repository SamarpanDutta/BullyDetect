{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Evaluation\n",
    "\n",
    "This Python notebook is used for evaluation of a dictionary that is produced by:\n",
    "\n",
    "- Find the cluster a word belongs to \n",
    "- Find the other words in the cluster for a specific word\n",
    "- Compare between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "# Specify the files\n",
    "FILE_DICT_500 = \"C:/Users/MyPC/Desktop/Vegito/Word Dictionaries/dict_500C.pk\"\n",
    "FILE_CLUS_500 = \"C:/Users/MyPC/Desktop/Vegito/K-Means Models/full_500C.pk\"\n",
    "\n",
    "# Load using pickle\n",
    "array_dict_cluster_500 = pickle.load(open(FILE_DICT_500, \"rb\"))\n",
    "word_centroid_map_500 =  pickle.load(open(FILE_CLUS_500,\"rb\"))\n",
    "\n",
    "total_clusters_500 = max(word_centroid_map_500.values()) + 1\n",
    "\n",
    "average_word_500 = round(len(word_centroid_map_500)/total_clusters_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER WORD TO SEARCH: olives\n",
      "SEARCHED WORD: olives \n",
      "\n",
      "TOTAL WORDS: 1565 \n",
      "\n",
      "\n",
      "\n",
      "furikake  crunchwrap  shiritaki  barbacoa  \n",
      "\n",
      "poultry  parathas  broil  quac  \n",
      "\n",
      "chowder  peppercorn  roasting  defrosted  \n",
      "\n",
      "blanch  mahi  sourdough  muffuletta  \n",
      "\n",
      "guisada  spaetzle  saganaki  kababs  \n",
      "\n",
      "sashimi  wholemeal  salads  meatsauce  \n",
      "\n",
      "sliced  cambozola  donairs  kebap  \n",
      "\n",
      "vegenaise  pho  braunschweiger  daiya  \n",
      "\n",
      "grassfed  marinaded  vegg  chanterelle  \n",
      "\n",
      "manchego  peper  kalbi  sauces  \n",
      "\n",
      "tilapia  birdseye  charcuterie  tunafish  \n",
      "\n",
      "galangal  lightlife  lasagne  stouffers  \n",
      "\n",
      "mandoline  bun  dinners  hotdogs  \n",
      "\n",
      "brunost  masalas  maseca  recipes  \n",
      "\n",
      "chutneys  yams  foie  steamed  \n",
      "\n",
      "jalfrezi  edamame  loin  collard  \n",
      "\n",
      "hotdog  fritters  tabouli  marinades  \n",
      "\n",
      "balti  chevre  precook  omelette  \n",
      "\n",
      "waygu  mung  mozerella  garnish  \n",
      "\n",
      "tostada  lavash  satay  salted  \n",
      "\n",
      "jackfruit  rashers  taquitos  fattiest  \n",
      "\n",
      "pestle  julienned  topping  tataki  \n",
      "\n",
      "inedible  sirracha  guanciale  scallops  \n",
      "\n",
      "jerkey  lutefisk  musubi  wyngz  \n",
      "\n",
      "gumbo  milksteak  broasted  eggwhites  \n",
      "\n",
      "vegtables  peperoni  kernals  linguini  \n",
      "\n",
      "microplane  talapia  horsemeat  jarred  \n",
      "\n",
      "kofta  groats  crust  spanikopita  \n",
      "\n",
      "tuna  schnitzels  matzah  escargot  \n",
      "\n",
      "latkes  kugel  cloves  peameal  \n",
      "\n",
      "provalone  chilli  pan  maruchan  \n",
      "\n",
      "breadcrumbs  zuppa  relish  peperoncini  \n",
      "\n",
      "chiffonade  peelings  bibimbap  florets  \n",
      "\n",
      "veggies  tostones  hellmann  tasso  \n",
      "\n",
      "allspice  saute  margherita  brined  \n",
      "\n",
      "soy  mangalitsa  wok  frittata  \n",
      "\n",
      "sardines  matza  paellas  dicer  \n",
      "\n",
      "deboned  tater  etouffee  oversalted  \n",
      "\n",
      "szechuan  schnitty  steak  boursin  \n",
      "\n",
      "burger  balut  tikka  chedder  "
     ]
    }
   ],
   "source": [
    "# Find the cluster of words, based on a given word\n",
    "search = input(\"ENTER WORD TO SEARCH: \")\n",
    "\n",
    "# Get the key, or cluster number\n",
    "# NOTE: Different clusters can have same results\n",
    "cluster_num_500 = word_centroid_map_500[search]\n",
    "\n",
    "# Return the array based on the cluster number\n",
    "words_500 = array_dict_cluster_500[cluster_num_500]['word_list']\n",
    "\n",
    "# Randomly subsample 200 words\n",
    "words = random.sample(words_500, 200)\n",
    "\n",
    "# Display results\n",
    "print(\"SEARCHED WORD: %s \\n\" % (search))\n",
    "\n",
    "print(\"TOTAL WORDS: %i \\n\" % (len(words_500)))\n",
    "\n",
    "# Pretty Printing\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    if i % 5 != 0:\n",
    "        print(word, \" \", end=\"\")\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
