{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation (Balanced Dataset)\n",
    "\n",
    "This Python notebook is to visualize the results from the experiments conducted. All methods were validated using Stratified 10 Fold Sampling. The utilized dataset consisted of 50% True Negative comments and 50% True Positive.\n",
    "\n",
    "## Classifiers \n",
    "\n",
    "The following classifiers were used:\n",
    "\n",
    "- Random Forest with 100 trees\n",
    "- Support Vector Machine (LinearSVC from sklearn)\n",
    "- Naive Bayes (Gaussian Naive Bayes)\n",
    "\n",
    "## Methods \n",
    "\n",
    "The following methods for classification were used:\n",
    "\n",
    "- Bag-Of-Words (Coming Soon)\n",
    "- Bag-Of-words + TFIDF (Coming Soon)\n",
    "- Average Sentence (Coming Soon)\n",
    "- Average Words (Coming Soon)\n",
    "- Average Words + TFIDF (Coming Soon)\n",
    "- Average Words + Mean Similarity (Hybrid Approach) (Coming Soon)\n",
    "- Average Words + Mean Similarity + TFIDF (Hybrid Approach) (Coming Soon)\n",
    "- Word Feature (Coming Soon)\n",
    "- Word Feature + TFIDF (Coming Soon)\n",
    "- Word Feature + Mean Similarity (Coming Soon)\n",
    "- Word Feature + Mean Similarity + TFIDF (Coming Soon)\n",
    "- K-Means Frequency Clustering (Coming Soon)\n",
    "- K-Means POS Style (Coming Soon)\n",
    "- K-Means Mean similarity Cluster (Coming Soon)\n",
    "- K-Means Mean similarty + TFIDF (Coming Soon)\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "The following evaluation metrics were taken under consideration:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- False Positive Rate\n",
    "- Area Under Curve (AUC) \n",
    "- Logarithmic Loss (Log Loss)\n",
    "- Brier Score Loss\n",
    "- Run Time for test set\n",
    "\n",
    "The Standard Deviation for all metrics were also taken into consideration\n",
    "\n",
    "## Overall Mean\n",
    "\n",
    "The mean scores from all methods were calculated and displayed using a barchart. The following metrics were:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- False Positive Rate\n",
    "- Area Under Curve (AUC)\n",
    "- Logarithmic Loss (Log Loss)\n",
    "- Brier Score Loss\n",
    "- Run Time"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
