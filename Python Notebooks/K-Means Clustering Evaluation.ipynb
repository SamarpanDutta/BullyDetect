{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Evaluation\n",
    "\n",
    "This Python notebook is used for evaluation of a dictionary that is produced by:\n",
    "\n",
    "- Find the cluster a word belongs to \n",
    "- Find the other words in the cluster for a specific word\n",
    "- Compare between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "# Specify the files\n",
    "FILE_DICT_500 = \"C:/Users/MyPC/Desktop/Vegito/Word Dictionaries/dict_500C.pk\"\n",
    "FILE_CLUS_500 = \"C:/Users/MyPC/Desktop/Vegito/K-Means Models/full_500C.pk\"\n",
    "\n",
    "# Load using pickle\n",
    "array_dict_cluster_500 = pickle.load(open(FILE_DICT_500, \"rb\"))\n",
    "word_centroid_map_500 =  pickle.load(open(FILE_CLUS_500,\"rb\"))\n",
    "\n",
    "total_clusters_500 = max(word_centroid_map_500.values()) + 1\n",
    "\n",
    "average_word_500 = round(len(word_centroid_map_500)/total_clusters_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER WORD TO SEARCH: doflamingo\n",
      "SEARCHED WORD: doflamingo \n",
      "\n",
      "TOTAL WORDS: 2020 \n",
      "\n",
      "\n",
      "\n",
      "laffitte  juzuo  kataras  kenpachi  \n",
      "\n",
      "isshins  hecuo  vali  rokushiki  \n",
      "\n",
      "majuub  recoome  byakugan  goshinki  \n",
      "\n",
      "unohanas  radditz  torquasm  kido  \n",
      "\n",
      "yammamoto  tessai  iihiko  tagashi  \n",
      "\n",
      "kanassans  saiyans  sandbend  reaitsu  \n",
      "\n",
      "haoshoku  bardock  hollowification  kishin  \n",
      "\n",
      "shabody  kyubii  dressrosa  uroge  \n",
      "\n",
      "tamakoma  sanin  bellemere  hirudegarn  \n",
      "\n",
      "chlammy  nougami  tenryuubito  deidera  \n",
      "\n",
      "geppou  hyousube  kacchan  hokage  \n",
      "\n",
      "shabondy  gaibon  prepgod  koromon  \n",
      "\n",
      "tullece  sasakibe  justsu  mutaito  \n",
      "\n",
      "teridax  kyros  tohja  shokan  \n",
      "\n",
      "genos  ukitakes  zancrow  dedoria  \n",
      "\n",
      "fraccion  plotkai  kuivira  jinbe  \n",
      "\n",
      "tosen  tenrou  rukias  genryuusai  \n",
      "\n",
      "budou  luffi  zommari  piccolo  \n",
      "\n",
      "ussopp  fough  wanze  destructo  \n",
      "\n",
      "polybotes  majjin  ywachs  waterbend  \n",
      "\n",
      "zorc  bikaku  krilin  grandline  \n",
      "\n",
      "lucci  butai  septar  sandai  \n",
      "\n",
      "nrvnqsr  daizenshuu  kaioshins  nen  \n",
      "\n",
      "dorry  rubberyness  yamacha  gaang  \n",
      "\n",
      "nozarashi  sakanade  jin  jonins  \n",
      "\n",
      "blooma  akoji  majiin  vageta  \n",
      "\n",
      "zanpaktou  izuna  seretei  ryuken  \n",
      "\n",
      "menoly  kachidoki  chomei  poundman  \n",
      "\n",
      "shippiden  aaroniero  etemon  shigan  \n",
      "\n",
      "hirou  mumkhar  jamemba  shingami  \n",
      "\n",
      "hozukimaru  keneki  sttgl  offscreens  \n",
      "\n",
      "homunculi  dodon  eustass  outspeeded  \n",
      "\n",
      "garou  scouter  racoom  unalaq  \n",
      "\n",
      "heuco  oozaru  manshelly  zzigg  \n",
      "\n",
      "haeru  marluxia  soulscape  suzumebachi  \n",
      "\n",
      "kugi  oracion  hashwald  jeece  \n",
      "\n",
      "krillin  zhaofu  mariejois  vergo  \n",
      "\n",
      "takeda  todoroki  kentipede  reiatsu  \n",
      "\n",
      "kojiro  kuzan  yamu  senpu  \n",
      "\n",
      "yakone  jyuubi  fukuro  susanoos  "
     ]
    }
   ],
   "source": [
    "# Find the cluster of words, based on a given word\n",
    "search = input(\"ENTER WORD TO SEARCH: \")\n",
    "\n",
    "# Get the key, or cluster number\n",
    "# NOTE: Different clusters can have same results\n",
    "cluster_num_500 = word_centroid_map_500[search]\n",
    "\n",
    "# Return the array based on the cluster number\n",
    "words_500 = array_dict_cluster_500[cluster_num_500]['word_list']\n",
    "\n",
    "# Randomly subsample 200 words\n",
    "words = random.sample(words_500, 200)\n",
    "\n",
    "# Display results\n",
    "print(\"SEARCHED WORD: %s \\n\" % (search))\n",
    "\n",
    "print(\"TOTAL WORDS: %i \\n\" % (len(words_500)))\n",
    "\n",
    "# Pretty Printing\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    if i % 5 != 0:\n",
    "        print(word, \" \", end=\"\")\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
