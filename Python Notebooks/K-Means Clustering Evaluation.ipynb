{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Evaluation\n",
    "\n",
    "This Python notebook is used for evaluation of a dictionary that is produced by:\n",
    "\n",
    "1. Clustering word vectors by K-Means clustering\n",
    "2. Converting into a dictionary that corresponds to 'Word: Index' pairing\n",
    "\n",
    "The evaluation consists of:\n",
    "\n",
    "- Find the cluster a word belongs to \n",
    "- Find the other words in the cluster for a specific word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL WORDS: 1146604\n",
      "TOTAL CLUSTERS USED: 500 \n",
      "AVERAGE PER CLUSTER 2293\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the files\n",
    "FILE_DICT = \"C:/Users/MyPC/Desktop/FYP/Word Dictionaries/dict_500C.pk\"\n",
    "FILE_CLUS = \"C:/Users/MyPC/Desktop/FYP/K-Means Models/full_500C.pk\"\n",
    "\n",
    "# Load using pickle\n",
    "array_dict_cluster = pickle.load(open(FILE_DICT, \"rb\"))\n",
    "word_centroid_map =  pickle.load(open(FILE_CLUS,\"rb\"))\n",
    "\n",
    "total_clusters = max(word_centroid_map.values()) + 1\n",
    "average_word = round(len(word_centroid_map)/total_clusters)\n",
    "\n",
    "# Display results\n",
    "print(\"TOTAL WORDS: %i\" % (len(word_centroid_map)))\n",
    "print(\"TOTAL CLUSTERS USED: %i \" % (total_clusters))\n",
    "print(\"AVERAGE PER CLUSTER %i\" % (average_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER NUMBER: 124\n",
      "SEARCHED WORD: convolutions \n",
      "\n",
      "INDEX NUMBER: 11\n",
      "words[11] = convolutions \n",
      "\n",
      "TOTAL WORDS: 1694 \n",
      "\n",
      "WORDS:  ['commutation', 'distributive', 'bayesian', 'endogeneity', 'matricies', 'associativity', 'compactness', 'hermitian', 'numerator', 'submanifolds', 'uncountable', 'convolutions', 'invariant', 'polytope', 'theorical', 'overconstrained', 'eigendecomposition', 'observationally', 'boundedness', 'discriminant', 'brzozowski', 'tangency', 'parametrization', 'entropies', 'wasserstein', 'precalculated', 'baconian', 'asymptote', 'congruential', 'visualised', 'permuting', 'arccos', 'subranges', 'spacelike', 'factorable', 'kinematics', 'homography', 'riemman', 'renormalizability', 'theoy', 'method', 'autoregression', 'lognormal', 'superposition', 'quantization', 'octet', 'renormalizable', 'relativities', 'pseudovector', 'sines', 'microarrays', 'hashlife', 'summands', 'probabilty', 'nabla', 'monomial', 'sinusoidal', 'borromean', 'transversality', 'pythagorus', 'transitivity', 'malleability', 'fibbonacci', 'dimensionless', 'minima', 'hillshade', 'epicycle', 'computations', 'fixity', 'differental', 'subproblems', 'subtest', 'hamiltonian', 'siteswaps', 'banach', 'truncating', 'chartjunk', 'stardates', 'timestep', 'laguerre', 'sigmoidal', 'endomorphisms', 'bedmas', 'eratosthenes', 'immutable', 'kruskal', 'multiphysics', 'subdividing', 'eigenspaces', 'tarjan', 'disad', 'describable', 'enderton', 'antiderivative', 'poset', 'noncommutative', 'lambda', 'regularize', 'bernoulli', 'univariate', 'reweight', 'cyclotomic', 'algorithim', 'divisible', 'instantiations', 'conics', 'statistical', 'cyclic', 'voronoi', 'mathemagical', 'tractable', 'thevenin', 'kalman', 'creational', 'homeomorphisms', 'superconformal', 'gaussian', 'skewes', 'bernouli', 'totient', 'leontief', 'integrands', 'radicand', 'differencing', 'constructable', 'hypergeometric', 'expressible', 'menten', 'adadelta', 'homomorphisms', 'hyperreals', 'backtested', 'classifier', 'weisbach', 'kervaire', 'datums', 'majorization', 'lexicographical', 'indetermination', 'trinomials', 'convexity', 'linest', 'posedness', 'uninterpretable', 'distinguishability', 'eigenstates', 'rmsprop', 'autocorrelation', 'spacially', 'condorcet', 'squarefree', 'wallenius', 'mathemathical', 'enumerative', 'softmax', 'factorise', 'trigram', 'cosecant', 'arithmetics', 'dataset', 'indeterminant', 'quotient', 'modulo', 'polytime', 'nanodrop', 'megaregions', 'circulant', 'subgraph', 'discretized', 'completeness', 'ciphertexts', 'deterministically', 'probablility', 'backcasting', 'autoencoder', 'backtracker', 'spatial', 'chern', 'tolerancing', 'triangulation', 'collinearity', 'translationally', 'textit', 'monoidal', 'morphism', 'nonzero', 'heteroscedastic', 'trigonomic', 'inelegance', 'antisymmetric', 'orthonormality', 'eucledian', 'approximator', 'sexagesimal', 'pardox', 'divisors', 'radians', 'cryptanalysis', 'rsquared', 'inversive']\n"
     ]
    }
   ],
   "source": [
    "# Find the cluster of words, based on a given word\n",
    "search = \"convolutions\"\n",
    "\n",
    "# Get the key, or cluster number\n",
    "cluster_num = word_centroid_map[search]\n",
    "\n",
    "# Return the array based on the cluster number\n",
    "words = array_dict_cluster[cluster_num]['word_list']\n",
    "        \n",
    "# Get index number of word (VERIFICATION)\n",
    "index_search = words.index(search)\n",
    "\n",
    "# Display results\n",
    "print(\"CLUSTER NUMBER: %i\" % (cluster_num))\n",
    "print(\"SEARCHED WORD: %s \\n\" % (search))\n",
    "\n",
    "print(\"INDEX NUMBER: %i\" % (index_search))\n",
    "print(\"words[%i] = %s \\n\" % (index_search, words[index_search]))\n",
    "\n",
    "print(\"TOTAL WORDS: %i \\n\" % (len(words)))\n",
    "\n",
    "print(\"WORDS: \", words[:200])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
